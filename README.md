# ğŸ¤Ÿ SIGNS OF PEOPLE

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg?logo=python&logoColor=white)
![Flet](https://img.shields.io/badge/Flet-Framework-purple.svg)
![MediaPipe](https://img.shields.io/badge/MediaPipe-ML-orange.svg?logo=google&logoColor=white)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-en%20desarrollo-yellow.svg)

**Traductor de Lenguaje de SeÃ±as impulsado por IA**

*Rompiendo barreras de comunicaciÃ³n para un mundo mÃ¡s inclusivo* ğŸŒ

[Demo](#) â€¢ [DocumentaciÃ³n](#) â€¢ [Reportar Bug](https://github.com/7749P-AR/Program_analythic_finger/issues)

---

</div>

## ğŸ¯ Sobre el Proyecto

**Signs of People** es un proyecto de impacto social que utiliza inteligencia artificial y visiÃ³n por computadora para traducir lenguaje de seÃ±as en tiempo real. DiseÃ±ado como herramienta de inclusiÃ³n para personas sordomudas y con discapacidades auditivas.

> ğŸ’¡ Este proyecto nace de la necesidad de crear puentes de comunicaciÃ³n accesibles y tecnolÃ³gicos para la comunidad sorda.

### âœ¨ CaracterÃ­sticas Principales

ğŸ¥ **TraducciÃ³n Visual â†’ Texto/Audio**
- Captura lenguaje de seÃ±as mediante cÃ¡mara web
- ConversiÃ³n instantÃ¡nea a texto escrito
- SÃ­ntesis de voz para output auditivo

âœï¸ **TraducciÃ³n Texto/Voz â†’ SeÃ±as**
- Input por teclado o micrÃ³fono
- RepresentaciÃ³n visual de seÃ±as en pantalla
- Animaciones fluidas y naturales

ğŸš€ **Multiplataforma**
- Modo Desktop (aplicaciÃ³n nativa)
- Modo Web Browser (acceso desde navegador)
- Arquitectura adaptable para futuro mobile

## ğŸ”® VisiÃ³n Futura

Con el apoyo de la comunidad, el proyecto expandirÃ¡ sus capacidades:

- ğŸ†˜ **Sistema de emergencias** para personas con discapacidad
- ğŸ’¼ **IntegraciÃ³n laboral** con herramientas empresariales
- ğŸŒ **Soporte multiidioma** de lenguajes de seÃ±as
- ğŸ“± **App mÃ³vil nativa** (iOS/Android)
- ğŸ¤ **Modo colaborativo** para videollamadas

## ğŸ› ï¸ Stack TecnolÃ³gico

- **Lenguaje**: Python 3.9+
- **Framework UI**: Flet (Flutter para Python)
- **Computer Vision**: MediaPipe (Google)
- **Machine Learning**: TensorFlow / OpenCV
- **Speech**: pyttsx3 / SpeechRecognition

## ğŸ“¦ InstalaciÃ³n

### Prerrequisitos

- Python 3.9 o superior
- pip (gestor de paquetes)
- CÃ¡mara web funcional
- Git

### Paso 1: Clonar el repositorio

```bash
git clone https://github.com/7749P-AR/Program_analythic_finger.git
cd Program_analythic_finger
```

### Paso 2: Crear entorno virtual

```bash
python -m venv .venv
```

### Paso 3: Activar entorno virtual

**Windows (PowerShell/CMD):**
```bash
.venv\Scripts\activate
```

**Linux/Mac:**
```bash
source .venv/bin/activate
```

> âš ï¸ **Â¿Scripts bloqueados en Windows?**
> 
> Abre PowerShell como **Administrador** y ejecuta:
> ```powershell
> Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
> ```
> 
> O para solo la sesiÃ³n actual:
> ```powershell
> Set-ExecutionPolicy -ExecutionPolicy Bypass -Scope Process
> ```

### Paso 4: Instalar dependencias

```bash
pip install -r requirements.txt
```

> ğŸ’¡ **Tip**: Si VS Code no reconoce el intÃ©rprete:
> - Presiona `Ctrl+Shift+P`
> - Busca "Python: Select Interpreter"
> - Selecciona el que termine en `(.venv)`

### Paso 5: Â¡Ejecutar!

```bash
python main.py
```

## ğŸ® Modos de EjecuciÃ³n

### Modo Web Browser (Por defecto)

```python
# main.py - lÃ­nea 385
ft.app(
    target=main,
    view=ft.AppView.WEB_BROWSER,  # Modo web
)
```

### Modo Desktop

Comenta o elimina la lÃ­nea `view=ft.AppView.WEB_BROWSER,`:

```python
# main.py - lÃ­nea 385
ft.app(
    target=main,
    # view=ft.AppView.WEB_BROWSER,  # â† Comentado
)
```

## ğŸ—‚ï¸ Estructura del Proyecto

```
Program_analythic_finger/
â”‚
â”œâ”€â”€ main.py                 # Punto de entrada principal
â”œâ”€â”€ requirements.txt        # Dependencias del proyecto
â”œâ”€â”€ README.md              # Este archivo
â”‚
â”œâ”€â”€ .venv/                 # Entorno virtual (no subir a Git)
â”œâ”€â”€ assets/                # Recursos multimedia
â”œâ”€â”€ models/                # Modelos ML entrenados
â””â”€â”€ utils/                 # Funciones auxiliares
```

## ğŸ¤ Contribuir

Â¡Las contribuciones son bienvenidas! Este proyecto busca mejorar vidas.

1. Fork el proyecto
2. Crea tu rama (`git checkout -b feature/MejorIncreible`)
3. Commit tus cambios (`git commit -m 'Add: nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/MejorIncreible`)
5. Abre un Pull Request

### Ideas para contribuir

- ğŸ› Reportar bugs
- ğŸ’¡ Sugerir nuevas caracterÃ­sticas
- ğŸ“ Mejorar documentaciÃ³n
- ğŸŒ Traducir a otros idiomas
- ğŸ¨ DiseÃ±ar interfaces mÃ¡s accesibles

## ğŸ“„ Licencia

Este proyecto es de **cÃ³digo abierto** y libre uso bajo licencia MIT.

### Reconocimientos de LibrerÃ­as

- **MediaPipe** Â© Google LLC - Apache License 2.0
- **Flet** - Apache License 2.0
- Todas las librerÃ­as mantienen sus licencias originales

## ğŸ‘¨â€ğŸ’» Autor

**Piero Abal Robles**  
*Ingeniero de Sistemas* ğŸš€

- GitHub: [@7749P-AR](https://github.com/7749P-AR)
- Universidad: UNHEVAL
- Proyecto: Impacto Social + Autoaprendizaje

## ğŸ™ Agradecimientos

Este proyecto estÃ¡ dedicado a:
- La comunidad sorda y sus defensores
- Personas que trabajan por la inclusiÃ³n
- Desarrolladores de MediaPipe y Flet
- Comunidad open source de Python

---

<div align="center">

**Â¿Te gustÃ³ el proyecto?** â­ Dale una estrella en GitHub

**Construido con â¤ï¸ para un mundo mÃ¡s inclusivo**

[â¬† Volver arriba](#-signs-of-people)

</div>

---

## ğŸŒ English Version

> *For international contributors and users*

### About

**Signs of People** is an AI-powered sign language translator built with Python, using MediaPipe for real-time hand tracking and gesture recognition.

### Quick Start

```bash
git clone https://github.com/7749P-AR/Program_analythic_finger.git
cd Program_analythic_finger
python -m venv .venv
.venv\Scripts\activate  # Windows
pip install -r requirements.txt
python main.py
```

### Features

- Real-time sign language to text/speech
- Text/speech to sign language animation
- Cross-platform (Desktop & Web)
- Built with accessibility in mind

---

*Last updated: October 2025*
